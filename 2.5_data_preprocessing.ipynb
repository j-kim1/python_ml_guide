{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "floral-memorabilia",
   "metadata": {},
   "source": [
    "### Data encoding\n",
    "- label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informed-water",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded value: [5 4 2 0 1 1 3 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "items = ['TV','Refrigerator','Microwave','Computer','Fan','Fan','Mixer','Mixer']\n",
    "#LabelEncoder object creation -> fit->trnasform\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print('encoded value:', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minute-election",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding classes: ['Computer' 'Fan' 'Microwave' 'Mixer' 'Refrigerator' 'TV']\n"
     ]
    }
   ],
   "source": [
    "print('encoding classes:', encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "registered-custom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded original: ['TV' 'Refrigerator' 'Microwave' 'Computer' 'Fan' 'Fan' 'Mixer' 'Mixer']\n"
     ]
    }
   ],
   "source": [
    "print('decoded original:', encoder.inverse_transform([5,4,2,0,1,1,3,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "illegal-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding is appropriate for the tree algorithm\n",
    "# not appropriate for the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "republican-thailand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding data\n",
      "[[0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]]\n",
      "one-hot encoding data shape\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "# Befor applying one-hot encoder, all data should be transformed to int type(using LabelEncoder) and 2D array shape\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "labels = labels.reshape(-1,1) # transform to 2D array\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "print('one-hot encoding data')\n",
    "print(oh_labels.toarray())\n",
    "print('one-hot encoding data shape')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "communist-national",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_Computer</th>\n",
       "      <th>item_Fan</th>\n",
       "      <th>item_Microwave</th>\n",
       "      <th>item_Mixer</th>\n",
       "      <th>item_Refrigerator</th>\n",
       "      <th>item_TV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_Computer  item_Fan  item_Microwave  item_Mixer  item_Refrigerator  \\\n",
       "0              0         0               0           0                  0   \n",
       "1              0         0               0           0                  1   \n",
       "2              0         0               1           0                  0   \n",
       "3              1         0               0           0                  0   \n",
       "4              0         1               0           0                  0   \n",
       "5              0         1               0           0                  0   \n",
       "6              0         0               0           1                  0   \n",
       "7              0         0               0           1                  0   \n",
       "\n",
       "   item_TV  \n",
       "0        1  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "5        0  \n",
       "6        0  \n",
       "7        0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'item':['TV','Refrigerator','Microwave','Computer','Fan','Fan','Mixer','Mixer']})\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-measure",
   "metadata": {},
   "source": [
    "### Feature scaling and standardization\n",
    "- StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "tamil-checklist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of features\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "variance of features\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data = iris.data, columns = iris.feature_names)\n",
    "print('mean of features')\n",
    "print(iris_df.mean())\n",
    "print('\\nvariance of features')\n",
    "print(iris_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "latin-world",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of features\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "variance of features\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler object creation\n",
    "scaler = StandardScaler()\n",
    "# call .fit() and .transform()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "# returned ndarray -> DataFrame\n",
    "iris_df_scaled = pd.DataFrame(data = iris_scaled, columns=iris.feature_names)\n",
    "print('mean of features')\n",
    "print(iris_df_scaled.mean())\n",
    "print('\\nvariance of features')\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-montana",
   "metadata": {},
   "source": [
    "- MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "tender-nightmare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum value of features\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "\n",
      "maximum value of features\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# MinMaxScaler object creation\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "#scaled ndarray -> DataFrame\n",
    "iris_df_scaled = pd.DataFrame(data = iris_scaled, columns = iris.feature_names)\n",
    "print('minimum value of features')\n",
    "print(iris_df_scaled.min())\n",
    "print('\\nmaximum value of features')\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-least",
   "metadata": {},
   "source": [
    "- Cautions for using scaler (need to use same object that is fitted already for the trainging data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "soviet-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "train_array = np.arange(0,11).reshape(-1,1)\n",
    "test_array = np.arange(0,6).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "demonstrated-april",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "scaled train_array: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array) #set as min 0, max 11\n",
    "train_scaled = scaler.transform(train_array) # 1/10 scaling \n",
    "print('original:', np.round(train_array.reshape(-1),2))\n",
    "print('scaled train_array:', np.round(train_scaled.reshape(-1),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "likely-japan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: [0 1 2 3 4 5]\n",
      "scaled test_array: [0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "#test array newly fitting againg (X)\n",
    "scaler.fit(test_array)\n",
    "test_scaled = scaler.transform(test_array) #1/5 scaling\n",
    "print('original:', np.round(test_array.reshape(-1),2))\n",
    "print('scaled test_array:', np.round(test_scaled.reshape(-1),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "conscious-hopkins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "scaled train_array: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "original: [0 1 2 3 4 5]\n",
      "scaled test_array: [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "test_scaled = scaler.transform(test_array)\n",
    "print('original:', np.round(train_array.reshape(-1),2))\n",
    "print('scaled train_array:', np.round(train_scaled.reshape(-1),2))\n",
    "print('original:', np.round(test_array.reshape(-1),2))\n",
    "print('scaled test_array:', np.round(test_scaled.reshape(-1),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-difficulty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
